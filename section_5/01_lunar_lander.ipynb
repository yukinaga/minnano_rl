{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_lunar_lander.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPojycpeTgR0T/AKDyJFIdD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yukinaga/minnano_rl/blob/main/section_5/01_lunar_lander.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6yMZqMzilIi"
      },
      "source": [
        "# 月面着陸船の制御\n",
        "深層強化学習を用いて月面着陸船（Lunar Lander）の制御を行います。  \n",
        "環境はOpenAI Gymのものを使用し、深層強化学習の実装にはStable Baselinesを利用します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKoLUHhtquWz"
      },
      "source": [
        "## ライブラリのインストール\n",
        "Stable Baselinesなどの必要なライブラリをインストールします。  \n",
        "ランタイムの再起動を求められた場合は、「ランタイム」→「ランタイムを再起動」によりランタイムを再起動します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlQSmVzWfTkS"
      },
      "source": [
        "!apt install swig cmake libopenmpi-dev zlib1g-dev\n",
        "!pip install stable-baselines==2.5.1 box2d box2d-kengz pyvirtualdisplay\n",
        "!apt-get install -y xvfb python-opengl ffmpeg\n",
        "!pip install tensorflow==1.14"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6J4qBnsuk2W"
      },
      "source": [
        "## ライブラリの導入\n",
        "OpenAI Gym、Stable Baselinesなどの各ライブラリを設定します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTl5LCDmgYKs"
      },
      "source": [
        "import os\n",
        "import io\n",
        "import glob\n",
        "import base64\n",
        "\n",
        "import gym\n",
        "from gym.wrappers import Monitor\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from stable_baselines.deepq.policies import MlpPolicy  # 2層のニューラルネットワーク\n",
        "from stable_baselines.common.vec_env import DummyVecEnv  # ベクトル化環境\n",
        "from stable_baselines import DQN\n",
        "from stable_baselines.common.vec_env import VecVideoRecorder\n",
        "\n",
        "from IPython import display as ipythondisplay\n",
        "from IPython.display import HTML\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WHD_xDuv2ez"
      },
      "source": [
        "## 環境の設定\n",
        "OpenAI Gymを使って月面着陸船の環境を設定します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gseF3CHuggrB"
      },
      "source": [
        "def env_func():\n",
        "    return gym.make(\"LunarLander-v2\")\n",
        "\n",
        "env_vec = DummyVecEnv([env_func])  # 環境のベクトル化が必要"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WabWYTBU5cfu"
      },
      "source": [
        "## モデル評価用の関数\n",
        "DQNのモデルを評価するための関数を用意します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnLYUk_XhuPK"
      },
      "source": [
        "def evaluate(env, model, n_step=10000, n_ave=100):\n",
        "\n",
        "  epi_rewards = [0.0]\n",
        "  states = env.reset()\n",
        "\n",
        "  for i in range(n_step):\n",
        "      action, _h = model.predict(states)  # _hはRNNで使用\n",
        "      states, rewards, dones, info = env.step(action)\n",
        "      \n",
        "      epi_rewards[-1] += rewards[0]  # 最後の要素に累積\n",
        "      if dones[0]:  # エピソード終了時\n",
        "          states = env.reset()\n",
        "          epi_rewards.append(0.0)  # 次のエピソードの報酬\n",
        "\n",
        "  ave_reward = round(np.average(epi_rewards[:n_ave]), 2)  # 最初の100エピソードで報酬の平均をとる\n",
        "  return (ave_reward, len(epi_rewards))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRBDKJ1Ds1Mh"
      },
      "source": [
        "## 動画表示用の関数\n",
        "結果を動画として表示するための関数を用意します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUyz1bxVig8d"
      },
      "source": [
        "os.system(\"Xvfb :1 -screen 0 1024x768x24 &\")\n",
        "os.environ['DISPLAY'] = ':1'\n",
        "\n",
        "def show_video(video_dir):\n",
        "  video_list = glob.glob(video_dir+\"/*.mp4\")\n",
        "  if len(video_list) > 0:\n",
        "    mp4 = video_list[0]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btjip0M2DIFb"
      },
      "source": [
        "## モデルの評価（訓練前）\n",
        "DQNのモデルを設定し、訓練前に評価します。  \n",
        "訓練前なので、月面着陸船はまともに着陸することはできません。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cE7_rnS1hxb3"
      },
      "source": [
        "env = VecVideoRecorder(env_vec, video_folder=\"videos_before_train/\",  # 動画記録の設定\n",
        "                            record_video_trigger=lambda step: step == 0, video_length=500,\n",
        "                            name_prefix=\"\")\n",
        "\n",
        "model = DQN(MlpPolicy, env, verbose=0)  # DQNの設定\n",
        "\n",
        "ave_reward, n_episode = evaluate(env, model, n_step=10000, n_ave=100)  # モデルの評価\n",
        "print(\"ave_reward:\", ave_reward, \"n_episode:\", n_episode)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjDFLLOatjK2"
      },
      "source": [
        "この時点での動作を動画で確認します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mVbi_QopaUQ"
      },
      "source": [
        "show_video(\"videos_before_train\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iN88dqTRFTDc"
      },
      "source": [
        "## モデルの訓練\n",
        "月面探索船が正しく着陸できるように、モデルを訓練します。  \n",
        "訓練済みのモデルは、いつでも利用できるように保存しておきます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZlM4r6Ih26w"
      },
      "source": [
        "trained_model = DQN(MlpPolicy, env_vec, verbose=0)  # モデルの初期化\n",
        "\n",
        "trained_model.learn(total_timesteps=100000)  # モデルの訓練\n",
        "trained_model.save(\"lunar_lander_control\")  # モデルの保存"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIGis_jwJ4xH"
      },
      "source": [
        "## 訓練済みモデルの評価\n",
        "学習が上手く進めば、月面着陸船は適切に着陸できるようになります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXYX1O9Oh9GH"
      },
      "source": [
        "env = VecVideoRecorder(env_vec, video_folder=\"videos_after_train/\",  # 動画記録の設定\n",
        "                            record_video_trigger=lambda step: step == 0, video_length=500,\n",
        "                            name_prefix=\"\")\n",
        "\n",
        "ave_reward, n_episode = evaluate(env, trained_model, n_step=10000, n_ave=100)  # モデルの評価\n",
        "print(\"ave_reward:\", ave_reward, \"n_episode:\", n_episode)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1JoclKLvDds"
      },
      "source": [
        "この時点での動作を動画で確認します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SD9qd_36vDd6"
      },
      "source": [
        "show_video(\"videos_after_train\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}